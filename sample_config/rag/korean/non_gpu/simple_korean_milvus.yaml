# =============================================================================
# AutoRAG 커스텀 서버 설정 파일 (Milvus Vector DB)
# =============================================================================
# 이 설정은 Milvus Vector DB를 사용합니다.
#
# 환경변수 설정 필요 (.env 파일):
#   - CUSTOM_LLM_API_BASE: LLM 서버 URL
#   - CUSTOM_LLM_MODEL: LLM 모델 이름
#   - CUSTOM_LLM_API_KEY: API 키
#   - CUSTOM_EMBEDDING_API_BASE: 임베딩 서버 URL
#   - CUSTOM_EMBEDDING_MODEL: 임베딩 모델
#   - MILVUS_HOST: Milvus 서버 호스트
#   - MILVUS_PORT: Milvus 서버 포트
#   - MILVUS_USER: Milvus 사용자
#   - MILVUS_PASSWORD: Milvus 비밀번호
#   - MILVUS_COLLECTION_NAME: Milvus 컬렉션 이름
#
# 실행 방법:
#   export $(cat .env | xargs)
#   autorag evaluate \
#     --config sample_config/rag/korean/non_gpu/simple_korean_milvus.yaml \
#     --qa_data_path tests/resources/dataset_sample_gen_by_autorag/qa.parquet \
#     --corpus_data_path tests/resources/dataset_sample_gen_by_autorag/corpus.parquet \
#     --project_dir logs
# =============================================================================

# =============================================================================
# 1단계: 벡터 데이터베이스 설정 (Milvus)
# =============================================================================
vectordb:
  - name: milvus_vectordb
    db_type: milvus
    uri: http://${MILVUS_HOST}:${MILVUS_PORT}
    user: ${MILVUS_USER}
    password: ${MILVUS_PASSWORD}
    collection_name: ${MILVUS_COLLECTION_NAME}
    embedding_batch: 100
    similarity_metric: cosine
    index_type: AUTOINDEX

    # 임베딩 모델 설정
    embedding_model:
      - type: openai_like
        model_name: ${CUSTOM_EMBEDDING_MODEL}
        api_base: ${CUSTOM_EMBEDDING_API_BASE}

# =============================================================================
# 2단계: RAG 파이프라인 정의 (node_lines)
# =============================================================================
node_lines:

  # ===========================================================================
  # 2-1. 검색 노드 라인 (Retrieve Node Line)
  # ===========================================================================
  - node_line_name: retrieve_node_line
    nodes:

      # -----------------------------------------------------------------------
      # 의미 기반 검색 (Semantic Retrieval)
      # -----------------------------------------------------------------------
      - node_type: semantic_retrieval

        strategy:
          metrics:
            - retrieval_f1
            - retrieval_recall
            - retrieval_precision

        top_k: 3

        modules:
          - module_type: vectordb
            vectordb: milvus_vectordb

  # ===========================================================================
  # 2-2. 후처리 노드 라인 (Post-Retrieve Node Line)
  # ===========================================================================
  - node_line_name: post_retrieve_node_line
    nodes:

      # -----------------------------------------------------------------------
      # 프롬프트 생성기 (Prompt Maker)
      # -----------------------------------------------------------------------
      - node_type: prompt_maker

        strategy:
          metrics:
            - bleu
            - meteor
            - rouge

        modules:
          - module_type: chat_fstring

            prompt:
              - - role: system
                  content: "주어진 passage만을 이용하여 질문에 답하시오."
                - role: user
                  content: "passage: {retrieved_contents}\n\nQuestion: {query}\n\nAnswer:"

      # -----------------------------------------------------------------------
      # 답변 생성기 (Generator)
      # -----------------------------------------------------------------------
      - node_type: generator

        strategy:
          metrics:
            - metric_name: rouge

        modules:
          - module_type: llama_index_llm

            llm: openailike
            model: ${CUSTOM_LLM_MODEL}
            api_base: ${CUSTOM_LLM_API_BASE}
            api_key: ${CUSTOM_LLM_API_KEY}

            is_chat_model: true
            temperature: 0.1
            timeout: 60
            max_tokens: 4096
