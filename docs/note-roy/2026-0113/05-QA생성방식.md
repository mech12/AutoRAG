# AutoRAG QA 생성 방식

테스트 케이스 실행 시 QA(질문-답변) 데이터가 어떻게 생성되고 설정되는지 정리합니다.

## QA 설정 위치 요약

| 설정 항목 | 파일 위치 |
| --------- | --------- |
| 테스트케이스 정의 | `scripts/test-config.yaml` |
| 생성된 QA 데이터 | `logs/testCase/{testcase}/data/qa.parquet` |
| QA 생성 로직 | `scripts/prepare_custom_data.py` |

## 1. 테스트 케이스 설정

`scripts/test-config.yaml` 파일에서 QA 관련 설정을 정의합니다:

```yaml
# 기본값 (테스트 케이스에서 생략 시 적용)
defaults:
  num_qa: 20        # 생성할 QA 쌍 개수
  use_llm: false    # LLM 사용 여부

# 테스트 케이스별 설정
test_cases:
  hr_rule:
    description: "취업규칙 PDF 기반 RAG 테스트"
    input_dir: "docs/sample-data/인사규정"
    output_dir: "logs/testCase/hr_rule"
    # 기본값 사용: num_qa=20, use_llm=false

  hr_rule_llm:
    description: "취업규칙 - LLM 사용 고품질 QA 생성"
    input_dir: "docs/sample-data/인사규정"
    output_dir: "logs/testCase/hr_rule_llm"
    num_qa: 50       # 더 많은 QA 생성
    use_llm: true    # LLM으로 실제 질문 생성
```

## 2. QA 생성 방식

### 2.1 Simple 모드 (기본값, LLM 없음)

`use_llm: false`일 때 사용되는 방식입니다.

**생성 로직** (`scripts/prepare_custom_data.py`의 `generate_qa_simple()` 함수):

```python
# 질문: 문서 내용 처음 100자를 기반으로 생성
qa_df["query"] = qa_df["retrieval_gt_contents"].apply(
    lambda x: f"다음 내용에 대해 설명해주세요: {x[0][0][:100]}..."
)

# 답변: 문서 내용 처음 500자
qa_df["generation_gt"] = qa_df["retrieval_gt_contents"].apply(
    lambda x: [x[0][0][:500]]
)
```

**생성되는 QA 예시**:

```text
[Q1] 다음 내용에 대해 설명해주세요: 파일 제목: 인사규정-07-취업규칙.pdf
     내용: 임신기 근로시간 단축을 사용하여 단축된 근로시간...

[A1] (문서 내용 처음 500자)
```

**장점**: 빠름, API 비용 없음
**단점**: 실제 질문이 아닌 플레이스홀더

### 2.2 LLM 모드 (고품질)

`use_llm: true`일 때 사용되는 방식입니다.

**생성 로직** (`scripts/prepare_custom_data.py`의 `generate_qa()` 함수):

```python
qa = (
    corpus_instance.sample(random_single_hop, n=num_qa)
    .make_retrieval_gt_contents()
    .batch_apply(
        factoid_query_gen,  # LLM으로 실제 질문 생성
        llm=llm,
        lang="ko",
    )
    .batch_apply(
        make_basic_gen_gt,  # LLM으로 답변 생성
        llm=llm,
        lang="ko",
    )
    .filter(
        dontknow_filter_rule_based,  # "모르겠다" 답변 필터링
        lang="ko",
    )
)
```

**필요한 환경변수** (`.env` 파일):

```bash
CUSTOM_LLM_API_BASE=https://llmserving.surromind.ai/v1
CUSTOM_LLM_MODEL=openai/gpt-oss-120b
CUSTOM_LLM_API_KEY=your-api-key
```

**장점**: 실제 사용자 질문과 유사한 고품질 QA
**단점**: API 비용 발생, 시간 소요

## 3. 생성된 QA 데이터 확인

### 3.1 Python으로 확인

```python
import pandas as pd

# QA 데이터 로드
qa = pd.read_parquet('logs/testCase/hr_rule/data/qa.parquet')

# 구조 확인
print(f'총 질문 수: {len(qa)}')
print(f'컬럼: {list(qa.columns)}')
# 출력: ['qid', 'query', 'retrieval_gt', 'generation_gt']

# 첫 번째 질문 확인
print(qa.iloc[0]['query'])
```

### 3.2 CLI로 확인

```bash
.venv/bin/python -c "
import pandas as pd
qa = pd.read_parquet('logs/testCase/hr_rule/data/qa.parquet')
for i, row in qa.head(5).iterrows():
    print(f'[Q{i+1}] {row[\"query\"][:80]}...')
"
```

## 4. QA 데이터 구조

생성된 `qa.parquet` 파일의 컬럼:

| 컬럼 | 설명 | 타입 |
| ---- | ---- | ---- |
| `qid` | 질문 고유 ID (UUID) | string |
| `query` | 질문 텍스트 | string |
| `retrieval_gt` | 정답 문서 ID 리스트 | list[list[string]] |
| `generation_gt` | 정답 텍스트 리스트 | list[string] |

**예시 데이터**:

```python
{
    'qid': 'a1b2c3d4-e5f6-...',
    'query': '연차휴가는 몇 일인가요?',
    'retrieval_gt': [['doc_id_1', 'doc_id_2']],  # 관련 문서 ID
    'generation_gt': ['연차휴가는 15일입니다.']   # 정답 텍스트
}
```

## 5. 커스텀 QA 직접 생성

### 5.1 수동으로 QA 파일 생성

```python
import pandas as pd
import uuid

# 직접 질문/답변 작성
qa_data = {
    'qid': [str(uuid.uuid4()) for _ in range(3)],
    'query': [
        '연차휴가는 몇 일인가요?',
        '수습기간은 얼마인가요?',
        '퇴직금 지급 기준은 무엇인가요?'
    ],
    'retrieval_gt': [
        [['doc_id_1']],
        [['doc_id_2']],
        [['doc_id_3']]
    ],
    'generation_gt': [
        ['연차휴가는 15일입니다.'],
        ['수습기간은 3개월입니다.'],
        ['1년 이상 근무 시 퇴직금이 지급됩니다.']
    ]
}

df = pd.DataFrame(qa_data)
df.to_parquet('logs/testCase/hr_rule/data/qa.parquet', index=False)
```

### 5.2 기존 QA 수정

```python
import pandas as pd

# 기존 QA 로드
qa = pd.read_parquet('logs/testCase/hr_rule/data/qa.parquet')

# 특정 질문 수정
qa.loc[0, 'query'] = '취업규칙에서 연차휴가 일수는?'
qa.loc[0, 'generation_gt'] = ['연간 15일의 유급휴가가 부여됩니다.']

# 저장
qa.to_parquet('logs/testCase/hr_rule/data/qa.parquet', index=False)
```

## 6. 평가 실행

QA 데이터가 준비되면 평가를 실행합니다:

```bash
# 방법 1: 테스트케이스로 실행
make run-testcase TESTCASE=hr_rule

# 방법 2: 데이터만 준비 후 평가
make prepare-data TESTCASE=hr_rule
make evaluate-custom TESTCASE=hr_rule

# 방법 3: 직접 autorag 명령 실행
autorag evaluate \
  --config sample_config/rag/korean/non_gpu/simple_korean.yaml \
  --qa_data_path logs/testCase/hr_rule/data/qa.parquet \
  --corpus_data_path logs/testCase/hr_rule/data/corpus.parquet \
  --project_dir logs/testCase/hr_rule/trial
```

## 7. 참고: QA 생성 관련 파일

```text
scripts/
├── test-config.yaml          # 테스트케이스 설정 (num_qa, use_llm)
├── prepare_custom_data.py    # QA 생성 스크립트
│   ├── generate_qa_simple()  # Simple 모드 (line 228-283)
│   └── generate_qa()         # LLM 모드 (line 152-225)
└── testcase_config.py        # 테스트케이스 로더

logs/testCase/{testcase}/data/
├── qa.parquet                # 생성된 QA 데이터
└── corpus.parquet            # 청크된 문서 데이터
```
