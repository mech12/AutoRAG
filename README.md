# AutoRAG

ë°ì´í„°ì— ìµœì í™”ëœ RAG íŒŒì´í”„ë¼ì¸ì„ ìë™ìœ¼ë¡œ ì°¾ì•„ì£¼ëŠ” RAG AutoML ë„êµ¬ì…ë‹ˆë‹¤.

![Thumbnail](https://github.com/user-attachments/assets/6bab243d-a4b3-431a-8ac0-fe17336ab4de)

![PyPI - Downloads](https://img.shields.io/pypi/dm/AutoRAG)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=flat-square&logo=linkedin)](https://www.linkedin.com/company/104375108/admin/dashboard/)
![X (formerly Twitter) Follow](https://img.shields.io/twitter/follow/AutoRAG_HQ)

ğŸ“– [ë¬¸ì„œ](https://marker-inc-korea.github.io/AutoRAG/) | ğŸ“‹ [ì „ì²´ README](README-org.md)

---

## ì„¤ì¹˜

Python 3.10 ì´ìƒ ê¶Œì¥

```bash
source .venv/bin/activate

# ê¸°ë³¸ ì„¤ì¹˜
pip install AutoRAG

# GPU ë²„ì „ (ë¡œì»¬ ëª¨ë¸ ì‚¬ìš© ì‹œ)
pip install "AutoRAG[gpu]"

# íŒŒì‹± ê¸°ëŠ¥ í¬í•¨
pip install "AutoRAG[gpu,parse]"
```

### ê°œë°œ í™˜ê²½ ì„¤ì¹˜

```bash
# uv ì‚¬ìš© (ê¶Œì¥)
uv venv && source .venv/bin/activate
uv sync --all-extras

# í•„ìˆ˜ í›„ì† ì„¤ì¹˜
pip install --upgrade pyOpenSSL nltk
python -c "import nltk; nltk.download('punkt_tab'); nltk.download('averaged_perceptron_tagger_eng')"
```

### ìë™ ê°€ìƒí™˜ê²½ í™œì„±í™” (direnv)

í”„ë¡œì íŠ¸ í´ë” ì§„ì… ì‹œ ìë™ìœ¼ë¡œ ê°€ìƒí™˜ê²½ í™œì„±í™”:

```bash
# 1. direnv ì„¤ì¹˜
brew install direnv

# 2. ì‰˜ ì„¤ì • ì¶”ê°€ (zsh)
echo 'eval "$(direnv hook zsh)"' >> ~/.zshrc
source ~/.zshrc

# 3. í”„ë¡œì íŠ¸ì— .envrc ìƒì„±
echo 'source .venv/bin/activate' > .envrc
direnv allow
```

---

## ì „ì²´ íë¦„

```
ì›ì‹œ ë¬¸ì„œ (PDF ë“±) â†’ íŒŒì‹± â†’ ì²­í‚¹ â†’ QA ìƒì„± â†’ RAG ìµœì í™”
                      â†“        â†“         â†“
              parsed.parquet  corpus.parquet  qa.parquet
```

---

## ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ìƒ˜í”Œ ë°ì´í„°)

```bash
# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export OPENAI_API_KEY="your-api-key"

# ìƒ˜í”Œ ë°ì´í„°ë¡œ RAG ìµœì í™” ì‹¤í–‰
autorag evaluate \
  --config sample_config/rag/korean/non_gpu/simple_korean.yaml \
  --qa_data_path tests/resources/dataset_sample_gen_by_autorag/qa.parquet \
  --corpus_data_path tests/resources/dataset_sample_gen_by_autorag/corpus.parquet

# ê²°ê³¼ ëŒ€ì‹œë³´ë“œ
autorag dashboard --trial_dir ./0
```

---

## ë°ì´í„° ìƒì„±

### 1. íŒŒì‹± ì„¤ì • (parse_config.yaml)

```yaml
modules:
  - module_type: langchain_parse
    parse_method: pdfminer
```

### 2. ì²­í‚¹ ì„¤ì • (chunk_config.yaml)

```yaml
modules:
  - module_type: llama_index_chunk
    chunk_method: Token
    chunk_size: 1024
    chunk_overlap: 24
    add_file_name: ko
```

### 3. ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸

```python
import os
os.environ["OPENAI_API_KEY"] = "your-api-key"

import pandas as pd
from llama_index.llms.openai import OpenAI
from autorag.parser import Parser
from autorag.chunker import Chunker
from autorag.data.qa.filter.dontknow import dontknow_filter_rule_based
from autorag.data.qa.generation_gt.llama_index_gen_gt import make_basic_gen_gt, make_concise_gen_gt
from autorag.data.qa.schema import Raw, Corpus
from autorag.data.qa.query.llama_gen_query import factoid_query_gen
from autorag.data.qa.sample import random_single_hop

# 1. íŒŒì‹±
parser = Parser(data_path_glob="data/*")
parser.start_parsing("parse_config.yaml")

# 2. ì²­í‚¹
chunker = Chunker.from_parquet(parsed_data_path="0/parsed.parquet")
chunker.start_chunking("chunk_config.yaml")

# 3. QA ìƒì„±
llm = OpenAI(model="gpt-4o-mini")
raw_df = pd.read_parquet("0/parsed.parquet")
raw_instance = Raw(raw_df)

corpus_df = pd.read_parquet("0/0/corpus.parquet")
corpus_instance = Corpus(corpus_df, raw_instance)

initial_qa = (
    corpus_instance.sample(random_single_hop, n=10)
    .map(lambda df: df.reset_index(drop=True))
    .make_retrieval_gt_contents()
    .batch_apply(factoid_query_gen, llm=llm)
    .batch_apply(make_basic_gen_gt, llm=llm)
    .batch_apply(make_concise_gen_gt, llm=llm)
    .filter(dontknow_filter_rule_based, lang="ko")
)

initial_qa.to_parquet('./qa.parquet', './corpus.parquet')
```

---

## RAG ìµœì í™” ì‹¤í–‰

```bash
# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export OPENAI_API_KEY="your-api-key"

# RAG ìµœì í™” ì‹¤í–‰
autorag evaluate \
  --config sample_config/rag/korean/non_gpu/simple_korean.yaml \
  --qa_data_path qa.parquet \
  --corpus_data_path corpus.parquet

# ê²°ê³¼ ëŒ€ì‹œë³´ë“œ
autorag dashboard --trial_dir ./0

# API ì„œë²„ ì‹¤í–‰
autorag run_api --trial_dir ./0 --host 0.0.0.0 --port 8000

# ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
autorag run_web --trial_path ./0
```

---

## CLI ëª…ë ¹ì–´

| ëª…ë ¹ì–´ | ì„¤ëª… |
|--------|------|
| `autorag evaluate` | RAG íŒŒì´í”„ë¼ì¸ í‰ê°€ ì‹¤í–‰ |
| `autorag validate` | ì„¤ì • íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬ |
| `autorag dashboard` | ê²°ê³¼ ëŒ€ì‹œë³´ë“œ ì‹¤í–‰ |
| `autorag run_api` | API ì„œë²„ ì‹¤í–‰ |
| `autorag run_web` | ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰ |

---

## ì°¸ê³  ìë£Œ

- [ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ](docs/note-roy/ë¹ ë¥¸í…ŒìŠ¤íŠ¸.md)
- [ì²­í‚¹(Chunking) ê°€ì´ë“œ](docs/note-roy/ì²­í‚¹ì—%20ëŒ€í•´.md)
- [ìƒ˜í”Œ ì„¤ì • íŒŒì¼](sample_config/rag)
- [ì§€ì› ëª¨ë“ˆ ëª©ë¡](https://edai.notion.site/Supporting-Nodes-modules-0ebc7810649f4e41aead472a92976be4)
- [ë¬¸ì œ í•´ê²°](https://medium.com/@autorag/autorag-troubleshooting-5cf872b100e3)

## ì¸ìš©

```bibtex
@misc{kim2024autoragautomatedframeworkoptimization,
      title={AutoRAG: Automated Framework for optimization of Retrieval Augmented Generation Pipeline},
      author={Dongkyu Kim and Byoungwook Kim and Donggeon Han and MatouÅ¡ Eibich},
      year={2024},
      eprint={2410.20878},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.20878},
}
```
